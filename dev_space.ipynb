{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b718b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "def greedy_ctc_decode(log_probs, phoneme_vocab, prob=True, blank_id=0):\n",
    "    \"\"\"\n",
    "    Converts frame-level log_probs (T x P) to phoneme sequence using greedy CTC decoding.\n",
    "\n",
    "    Args:\n",
    "        log_probs (Tensor): [T, P] log-probs over phoneme classes\n",
    "        phoneme_vocab (List[str]): ID-to-phoneme mapping\n",
    "        blank_id (int): Index of the CTC blank token\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Decoded phoneme sequence (collapsed)\n",
    "    \"\"\"\n",
    "    if prob:\n",
    "        pred_ids = torch.argmax(log_probs, dim=-1).tolist()\n",
    "    else:\n",
    "        pred_ids = log_probs.tolist()\n",
    "    seq = []\n",
    "    prev = None\n",
    "    for idx in pred_ids:\n",
    "        if idx != blank_id and idx != prev:\n",
    "            seq.append(phoneme_vocab[idx])\n",
    "        prev = idx\n",
    "    return seq\n",
    "\n",
    "\n",
    "def phoneme_error_rate(log_probs_ref, log_probs_hyp, phoneme_vocab, blank_id=0):\n",
    "    ref_seq = greedy_ctc_decode(log_probs_ref, phoneme_vocab, prob=False, blank_id=blank_id)\n",
    "    hyp_seq = greedy_ctc_decode(log_probs_hyp, phoneme_vocab, prob=True, blank_id=blank_id)\n",
    "\n",
    "    ref_str = ' '.join(ref_seq)\n",
    "    hyp_str = ' '.join(hyp_seq)\n",
    "    dist = levenshtein_distance(ref_str, hyp_str)\n",
    "    N = len(ref_seq)\n",
    "    per = dist / (N if N > 0 else 1)\n",
    "    return per, dist, N, ref_seq, hyp_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER: 1.111 (40 edits over 36 phonemes)\n"
     ]
    }
   ],
   "source": [
    "phoneme_vocab = ['_', 'ah', 'b', 'd', 'eh', 'f', 'g', 'k', 's', 't']  # example\n",
    "log_probs_ref = torch.randint(0, len(phoneme_vocab), (50,))  # [T, P]\n",
    "log_probs_hyp = torch.randn(50, len(phoneme_vocab))\n",
    "\n",
    "per, dist, N, r_seq, h_seq = phoneme_error_rate(log_probs_ref, log_probs_hyp, phoneme_vocab)\n",
    "print(f\"PER: {per:.3f} ({dist} edits over {N} phonemes)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0c48fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "class PhonemeErrorRate:\n",
    "    def __init__(self, phoneme_vocab, blank_id=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            phoneme_vocab (List[str]): ID-to-phoneme mapping\n",
    "            blank_id (int): ID of the CTC blank token\n",
    "        \"\"\"\n",
    "        self.phoneme_vocab = phoneme_vocab\n",
    "        self.blank_id = blank_id\n",
    "        self.total_edits = 0\n",
    "        self.total_ref_phonemes = 0\n",
    "        self.decoded_refs = []\n",
    "        self.decoded_hyps = []\n",
    "\n",
    "    def greedy_ctc_decode(self, log_probs, prob=True):\n",
    "        \"\"\"\n",
    "        Greedy CTC decoding from log_probs to phoneme sequence.\n",
    "        \n",
    "        Args:\n",
    "            log_probs (Tensor): shape [T, V]\n",
    "            prob (bool): If True, assumes input is log_probs from model output (hyp);\n",
    "                         If False, assumes manual or clean target (ref)\n",
    "        \n",
    "        Returns:\n",
    "            List[str]: Decoded phoneme sequence\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        if prob:\n",
    "            pred_ids = torch.argmax(log_probs, dim=-1).tolist()\n",
    "        else:\n",
    "            pred_ids = log_probs.tolist()\n",
    "        \n",
    "        seq = []\n",
    "        prev = None\n",
    "        for idx in pred_ids:\n",
    "            if idx == self.blank_id:\n",
    "                continue\n",
    "            if idx != prev:\n",
    "                seq.append(self.phoneme_vocab[idx])\n",
    "            prev = idx\n",
    "        return seq\n",
    "\n",
    "    def add_batch(self, log_probs_ref_batch, log_probs_hyp_batch):\n",
    "        \"\"\"\n",
    "        Add a batch of phoneme predictions and references.\n",
    "        \n",
    "        Args:\n",
    "            log_probs_ref_batch: List[Tensor] — reference log-probs per sample [T_i, V]\n",
    "            log_probs_hyp_batch: List[Tensor] — hypothesis log-probs per sample [T_i, V]\n",
    "        \"\"\"\n",
    "        for log_probs_ref, log_probs_hyp in zip(log_probs_ref_batch, log_probs_hyp_batch):\n",
    "            ref_seq = self.greedy_ctc_decode(log_probs_ref, prob=False)\n",
    "            hyp_seq = self.greedy_ctc_decode(log_probs_hyp, prob=True)\n",
    "\n",
    "            self.decoded_refs.append(ref_seq)\n",
    "            self.decoded_hyps.append(hyp_seq)\n",
    "\n",
    "            ref_str = ' '.join(ref_seq)\n",
    "            hyp_str = ' '.join(hyp_seq)\n",
    "            dist = levenshtein_distance(ref_str, hyp_str)\n",
    "\n",
    "            self.total_edits += dist\n",
    "            self.total_ref_phonemes += len(ref_seq)\n",
    "\n",
    "    def compute(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            per (float): Micro-average PER over all batches\n",
    "            total_edits (int): Total Levenshtein distance\n",
    "            total_ref_phonemes (int): Total number of reference phonemes\n",
    "        \"\"\"\n",
    "        per = self.total_edits / max(self.total_ref_phonemes, 1)\n",
    "        return per, self.total_edits, self.total_ref_phonemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0891c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro PER: 1.112 (179 edits over 161 phonemes)\n"
     ]
    }
   ],
   "source": [
    "log_probs_ref_batch = torch.randint(0, len(phoneme_vocab), (4, 50,))  # [T, P]\n",
    "log_probs_hyp_batch = torch.randn(4, 50, len(phoneme_vocab))\n",
    "\n",
    "# Assume phoneme_vocab is your ID-to-symbol list, blank_id is index of blank token\n",
    "per_metric = PhonemeErrorRate(phoneme_vocab, blank_id=0)\n",
    "\n",
    "# For each batch during eval:\n",
    "per_metric.add_batch(log_probs_ref_batch, log_probs_hyp_batch)\n",
    "\n",
    "# At the end:\n",
    "per, edits, total = per_metric.compute()\n",
    "print(f\"Micro PER: {per:.3f} ({edits} edits over {total} phonemes)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
